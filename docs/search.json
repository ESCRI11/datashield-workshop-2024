[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataSHIELD Workshop",
    "section": "",
    "text": "Funding\nThis course is an initiative developed by ISGlobal’s Health Analytics Hub, and has received support from the Generalitat de Catalunya through the CERCA Program and Ministry of Research and Universities (2021 SGR 01563) and the Spanish Ministry of Science and Innovation and Fondo Europeo de Desarrollo Regional, UE (PID2021-122855OB-I00). This course is part of WP3 of ATHLETE project.\n\n\nIntroduction\nThis website has been created to host the materials and exercises for the Advanced Users’ DataSHIELD Workshop, hosted at the Center for Mathematics of the University of Bonn Thursday 26th September 2024.\nOn it you will find reading materials, setup tutorials, the workshop indications and practical exercises.\n\n\nGetting started\nBefore the workshop we suggest the atendants to take a look at the “Environment setup” and “Get up to speed” sections. This way they will have their computers with the right software installed to follow the workshop.\nDue the nature of this workshop, the attendants are expected to have some notions of R package development, to cover the basics please follow the material available on the “Get up to speed” section, we suggest participants with limited knowledge of R package development to check that out before taking the workshop.\nIf the attendant is familiar with R package development, we just advice to follow the “Environment setup” to make sure we spend no time during the workshop installing packages.\n\n\nSchedule\nTo be delivered.\n\n\nCredits\nMaterials developed by Juan R. González (ISGlobal) and Xavier Escribà Montagut (BigOmics Analytics SA).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "env_setup.html",
    "href": "env_setup.html",
    "title": "Environment setup",
    "section": "",
    "text": "R packages\nIn order to develop, test and push our new DataSHIELD packages, we will require the following R packages to be installed:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment setup</span>"
    ]
  },
  {
    "objectID": "env_setup.html#install-guide",
    "href": "env_setup.html#install-guide",
    "title": "Environment setup",
    "section": "Install guide",
    "text": "Install guide\nWhen using R, we are used to installing packages with the handy install.packages() function. However, by default it uses the CRAN repository, which does not contain all the required packages. For that reason we provide a quick code snippet to install all the required packages:\n\n# Install DSLite\ninstall.packages(\"DSLite\")\n\n# Install DSI\ninstall.packages(\"DSI\")\n\n# Install dsBase\ninstall.packages(\n    'dsBase',\n    repos=c(\n        getOption('repos'),\n        'http://cran.datashield.org'\n    ),\n    dependencies=TRUE\n)\n\n# Install dsBaseClient\ninstall.packages(\n    'dsBaseClient',\n    repos=c(\n        getOption('repos'),\n        'http://cran.datashield.org'\n    ),\n    dependencies=TRUE\n)\n\nWith that, your environment will be ready to take on the workshop. Nevertheless, please read the next sessions to familiarize with R package development if you are not already.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment setup</span>"
    ]
  },
  {
    "objectID": "up_2_speed.html",
    "href": "up_2_speed.html",
    "title": "Get up to speed",
    "section": "",
    "text": "Developing your first R package\nDuring the workshop it will be assumed that the attendats have already prior knowledge about building a regular R package. If that was not the case, we provide some useful links to prepare in advance, as with the environment setup, feel free to contact the authors before the workshop to solve any doubts.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Get up to speed</span>"
    ]
  },
  {
    "objectID": "up_2_speed.html#developing-your-first-r-package",
    "href": "up_2_speed.html#developing-your-first-r-package",
    "title": "Get up to speed",
    "section": "",
    "text": "R packages\nusethis package\nroxygen2\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are not confident in your basic R package building skills, we suggest creating your first package before the workshop.\nA good exercise would be to use the usethis package to setup the basic R package structure, create a simple helloWorld() function and document it using roxygen2.\nHere, you can see how that would looke like once finished.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Get up to speed</span>"
    ]
  },
  {
    "objectID": "up_2_speed.html#footnotes",
    "href": "up_2_speed.html#footnotes",
    "title": "Get up to speed",
    "section": "",
    "text": "From Xavier Escribà↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Get up to speed</span>"
    ]
  },
  {
    "objectID": "1-datashield-packages-structure.html",
    "href": "1-datashield-packages-structure.html",
    "title": "1. DataSHIELD packages structure",
    "section": "",
    "text": "Naming conventions\nAs with many different software and architectures, there are a set of (somtimes un-) written rules that developers stick to. In this case, no official writting is available, so this document can serve as a starting point.\nFirst and foremost, use camelCase naming convention.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>1. DataSHIELD packages structure</span>"
    ]
  },
  {
    "objectID": "1-datashield-packages-structure.html#naming-conventions",
    "href": "1-datashield-packages-structure.html#naming-conventions",
    "title": "1. DataSHIELD packages structure",
    "section": "",
    "text": "Naming the client package\nThe naming for the client package will follow this rule\ndsXxxClient\nWhere Xxx is the actual name. E.g. a metabolomics exposome package could be named dsMetabolomicsClient.\n\n\nNaming of the server package\nThe server package will use the same Xxx and be named as\ndsXxx\nFollowing on the metabolomics example we would have dsMetabolomics.\n\n\nFunction naming on the client\nThe naming of functions on the client package will follow\nds.Xxx\nE.g. in metabolomics ds.ComputeMetaboScore.\n\n\nFunction naming on the server\nMost times a client function will call a specific one on the server, therefore we name them the same.\nXxxDS\nE.g. in metabolomics ComputeMetaboScoreDS.\nPlease note this is not a strict rule, it is just a good practice. If all developers stick to ~ similar ~ rules, the feel for the actual users will be smoother, which will improve engagement on the project.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>1. DataSHIELD packages structure</span>"
    ]
  },
  {
    "objectID": "1-datashield-packages-structure.html#dsi-communicating-from-client-to-server",
    "href": "1-datashield-packages-structure.html#dsi-communicating-from-client-to-server",
    "title": "1. DataSHIELD packages structure",
    "section": "DSI: Communicating from client to server",
    "text": "DSI: Communicating from client to server\nNow that we understand why two packages are required and how to name them, let’s see which tool we have to perform communications between them. The tool that we will use is called DSI, short for “DataSHIELD Interface”. This tool will allow us to send queries from the packages on the client to the server ones, as well as recieve the server response with the results that we want to use or show the the researcher.\n\n\n\n\n\n\nNote\n\n\n\nThe DSI package is also responsible for creating connections to the server (datashield.login), handling workspaces (datashield.workspaces) and many other stuff, this is not connected to package development.\n\n\n\nCommunication types\nWith DSI there are two different types of communications we can perform, one telling the server to assign the result of a function to a variable, the other telling the server to return the result of a function. It is important to notice that not any function can be used; we, as package developers, will develop a set of functions on the server package and each of them will only be available to be used one way or another, therefore, this information will be specified on the server package (see DATASHIELD file).\nGiven that these functions communicate from the client package to the server package, they will only be used on the client package. It is important to note that to function they will require the information to which servers to talk to, more on this in a second (The datasources object).\n\nAssign functions\nAssign functions, as the name implies, will assign something to the R session that is running on the server. For example if we have loaded a data table, we can write a function that takes the first two columns and assigns it to a new variable.\n\n\n\n\n\nsequenceDiagram\n    Client-&gt;&gt;+Server: Run `helloWorld()` and assign the results to a variable named \"hello\"\n    Server--&gt;&gt;-Client: Done deal boss (but in silence)\n\n\n\n\n\n\nPlease note that after running an assign function, the client does not recieve anything, hence (but in silence) on the diagram.\nCode-wise this will look like this\n\nDSI::datashield.assign.expr(\n  conns = conns,\n  symbol = \"hello\",\n  expr = call(\"helloWorld()\")\n)\n\nWe are passing to the DSI::datashield.assign.expr function 1 the conns object (more on this here The datasources object), 2 the variable where the result will be assigned on the server and 3 the function whose result will be assigned to the new variable.\n\n\nAggregate functions\nAggregate functions will run a function on the server and the result will be sent to the client. Beware, a poorly written function on the server might be able to return raw data to the client, completely defeating the point of using DataSHIELD. The process in this case looks like this\n\n\n\n\n\nsequenceDiagram\n    Client-&gt;&gt;+Server: Run `helloWorld()` and return me the results of it\n    Server--&gt;&gt;-Client: Done deal boss (sends data to the client)\n\n\n\n\n\n\nCode-wise this will look like this\n\nDSI::datashield.aggregate(\n  conns = conns,\n  expr = call(\"helloWorld()\")\n)\n\nHere in this case the function is returning something, so we can assign it myValue &lt;- DSI::datashield.aggregate(...) and use the value on the client, maybe we want to plot it or just send it to the user directly.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>1. DataSHIELD packages structure</span>"
    ]
  },
  {
    "objectID": "1-datashield-packages-structure.html#sec-ds-file",
    "href": "1-datashield-packages-structure.html#sec-ds-file",
    "title": "1. DataSHIELD packages structure",
    "section": "DATASHIELD file",
    "text": "DATASHIELD file\nAs we have just seen, from the client we can tell the server to run functions and assign the results to an object on the server, or to send the results to the client. However, we as developer can specify which functions are allowed to return values to the client, and which will assign it’s results to the server R session.\nTo do that we will add a file named DATASHIELD on our server. More precisely it will be located as follows\n.\n└── dsServer/\n    ├── R/\n    │   └── ds.function.R\n    ├── inst/\n    │   └── DATASHIELD\n    ├── DESCRIPTION\n    └── NAMESPACE\nThis file is a simple plain text file with the following structure\nAssignMethods:\n  myAssingFunc1DS,\n  myAssingFunc2DS\nAggregateMethods:\n  myAggregateFunc1DS,\n  myAggregateFunc2DS\nAlternatively, we can also include this information into the DESCRIPTION file of our server R package following the same formatting. Refer to dsBase DESCRIPTION file for an example.\n\n\n\n\n\n\nNote\n\n\n\nKeeping this information on a separate file guarantees a cleaner DESCRIPTION file, specially relevant for extense packages with many functions. Feel free to use any of the two methods at your own judgment.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>1. DataSHIELD packages structure</span>"
    ]
  },
  {
    "objectID": "1-datashield-packages-structure.html#sec-datasources",
    "href": "1-datashield-packages-structure.html#sec-datasources",
    "title": "1. DataSHIELD packages structure",
    "section": "The datasources object",
    "text": "The datasources object\nWe have been talking about communicating between the client and the server and telling the server to run things. However, we need some object that contains the information about which server are we talking to. This oject is created by the login functions on DataSHIELD. Here a brief example\n\nbuilder &lt;- DSI::newDSLoginBuilder()\nbuilder$append(server = \"myServer\",\n               url = \"https://myDSserver.org\",\n               user = \"ds_user\", password = \"password\")\nlogindata &lt;- builder$build()\nconnections &lt;- DSI::datashield.login(logins = logindata)\n\nThis connection object is what our DSI functions will use to know to which servers to talk. For that reason, on the client functions that we write we will put an argument to pass it. Typically this argument is named datasources and defaults to NULL. It can default to NULL because DSI offers a helper function to search for this object on the client R environment and use it; nevertheless it is important that we can let the user specify which connection object they want to use, maybe someone creates two different connection on the same session and wants to use a certain one with different functions.\nHere is how a typical client function starts and how to use this helper function from DSI\n\nds.Function &lt;- function(..., datasources = NULL){\n  \n  if (is.null(datasources)) {\n    datasources &lt;- DSI::datashield.connections_find()\n  }\n\n  # Rest of the function\n\n}\n\nYou can see that the function DSI::datashield.connections_find will find the connection object on the environment and use it during the rest of the function call.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>1. DataSHIELD packages structure</span>"
    ]
  },
  {
    "objectID": "1-datashield-packages-structure.html#exercise-1",
    "href": "1-datashield-packages-structure.html#exercise-1",
    "title": "1. DataSHIELD packages structure",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nCreate two R packages: dsClient and dsServer\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nMake your life easier by using usethis::create_package(\"dsClient\")\n\n\n\n\nOn the dsClient package create a function named ds.assignString that takes as input argument a string, and sends it to the assign function assignStringDS from the dsServer package.\n\n\n\n\n\n\n\nRemember\n\n\n\n\n\nAdd #' @export on top of your new R function to export it. Then, run devtools::document() so it gets added to the NAMESPACE file of your package automatically, this will allow you to library(dsClient) and be able to call ds.assignString.\n\n\n\n\nOn the dsServer package create a function named assignStringDS that takes as input argument a string, and returns that string.\nDeclare the assignStringDS as a DataSHIELD assign function.\n\n\n\n\n\n\n\nExercise solution\n\n\n\n\n\nOpen in new tab",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>1. DataSHIELD packages structure</span>"
    ]
  },
  {
    "objectID": "2-dslite.html",
    "href": "2-dslite.html",
    "title": "2. DSLite: Does my package work?",
    "section": "",
    "text": "Sending data to my virtual server\nThis simple example we have just seen is pretty nice. However, one might be thinking hey typically I want my server functions to analyze tabular data, which is loaded by the user on the server session and will be used by my functions. We can also simulate this on DSLite to test our packages. Let’s see an example where we will load iris data on the virtual server.\nlibrary(dsBase)\nlibrary(dsBaseClient)\ndata(\"iris\")\nmyTable &lt;- iris\nbuilder &lt;- DSI::newDSLoginBuilder()\ndslite.server &lt;- DSLite::newDSLiteServer(\n  tables=list(myTable = myTable),\n  config = DSLite::defaultDSConfiguration(\n    include=c(\"dsBase\")\n  )\n)\nbuilder$append(\n  server = \"server1\",\n  url = \"dslite.server\",\n  table = \"myTable\",\n  driver = \"DSLiteDriver\"\n)\nlogindata.dslite &lt;- builder$build()\nconns &lt;- DSI::datashield.login(\n  logins = logindata.dslite,\n  assign=T,\n  symbol = \"myTable_table\"\n)\nThis will assign the iris dataset to a variable on the server named \"myTable_table\". As before, we can check it\nDSLite::getDSLiteData(\n  conns = conns,\n  symbol = \"myTable_table\"\n)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>2. DSLite: Does my package work?</span>"
    ]
  },
  {
    "objectID": "2-dslite.html#sending-data-to-my-virtual-server",
    "href": "2-dslite.html#sending-data-to-my-virtual-server",
    "title": "2. DSLite: Does my package work?",
    "section": "",
    "text": "Pro tip\n\n\n\n\n\nWhen developing code, it is useful to be able to place debug points. This means being able to stop the execution on a certain point and look the environment, run code at that stop point etc. In R, a way of doing that is including browser() statements on the code (more on this here).\nDSLite offers us the possibility of adding them on the server functions, and when we run them the execution will be stopped so we can take debug server functions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>2. DSLite: Does my package work?</span>"
    ]
  },
  {
    "objectID": "2-dslite.html#exercise-2",
    "href": "2-dslite.html#exercise-2",
    "title": "2. DSLite: Does my package work?",
    "section": "Exercise 2",
    "text": "Exercise 2\nAs out second exercise of the workshop, we will work on top of Exercise 1 developments.\n\nCreate a new aggregate function (named getColnamesDS) on the dsServer package. This function will take as input argument a data table (that will be loaded on the server). It will return to the user the column names on the table.\nCreate the correspondent function on dsClient (named ds.getColnames) that calls the server function. This function will take as input argument the name of the server table that we want to get the number of columns.\nTest the new function using DSLite.\n\n\n\n\n\n\n\nExercise solution\n\n\n\n\n\nOpen in new tab",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>2. DSLite: Does my package work?</span>"
    ]
  },
  {
    "objectID": "3-datashield-filters.html",
    "href": "3-datashield-filters.html",
    "title": "3. DataSHIELD filters",
    "section": "",
    "text": "Options slot of an R package\nFilter values are only available on the server, as we do not want the analysts to be able to manipulate them, just the data owners. For that reason they are defined on the server packages. More precisely they are defined on the DATASHIELD file of the R package. Please note that as discussed on the previous section, this information could go to the DESCRIPTION file wit the declaration of aggregate and assign functions as additional metadata. Take a look for example at the dsBase DESCRIPTION file. During this workshop we will be using the DATASHIELD file.\nNow let’s continue by checking how to access those values within our package functions.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>3. DataSHIELD filters</span>"
    ]
  },
  {
    "objectID": "3-datashield-filters.html#accessing-a-filter-value",
    "href": "3-datashield-filters.html#accessing-a-filter-value",
    "title": "3. DataSHIELD filters",
    "section": "Accessing a filter value",
    "text": "Accessing a filter value\nIn order to retrieve the value of a filter on our package functions we will use the getOption function. If we want to retrieve the value of the my.new.filter filter, we will do:\n\ngetOption(\"my.new.filter\")\n\n\n\n\n\n\n\nNote\n\n\n\nIf we try to retrieve a value of an option that is not defined, it will return NULL, this can be convenient to handle exceptions.\n\n\nFollowing that we can see that if we want to use a filter from dsBase, we just have to take a look at the available ones and use them:\n\ngetOption(\"default.nfilter.glm\")\n\nAlso if we define our own filter (on our package DATASHIELD file):\n\nOptions:\n    nice.filter=5\n\n\n\n\n\n\n\nFurther info\n\n\n\n\n\nHere we see that the filter contains a numeric variable. However they are not limited to that, they can also contain strings and other R data types.\n\nOptions:\n    even.nicer.filter=\"hello\"\n\n\n\n\nWe retrieve it by:\n\ngetOption(\"nice.filter\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>3. DataSHIELD filters</span>"
    ]
  },
  {
    "objectID": "3-datashield-filters.html#exercise-3",
    "href": "3-datashield-filters.html#exercise-3",
    "title": "3. DataSHIELD filters",
    "section": "Exercise 3",
    "text": "Exercise 3\nFor this exercise, we will continue working on our new packges.\n\nCreate a new filter named myFilter. Set the default value as numeric 6.\nModify the getColnamesDS function to retrieve the myFilter value.\nIf the number of columns of the data frame is less than myFilter return an error.\n\n\n\n\n\n\n\nErrors in R\n\n\n\n\n\nIn R we can throw errors (or exceptions) using the stop function.\nE.g.\n\nstop(\"This is my error message\")\n\n\n\n\n\nTest your new development using DSLite. Does it throw the error we expect?\n\n\n\n\n\n\n\nExercise solution\n\n\n\n\n\nOpen in new tab",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>3. DataSHIELD filters</span>"
    ]
  },
  {
    "objectID": "4-datashield-pooled.html",
    "href": "4-datashield-pooled.html",
    "title": "4. Pooled and study-level functions",
    "section": "",
    "text": "Pooled analysis\nA pooled analysis in DataSHIELD is when the statistical result that the researcher recieves, is the same as if all the data of the combined studies were “pooled” together and the operation performed on that; however, when this is achieved in DataSHIELD, there is no patient-level data shared between the analysis servers, only (at most) aggregated statistics (e.g. on an iterative algorithm).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>4. Pooled and study-level functions</span>"
    ]
  },
  {
    "objectID": "4-datashield-pooled.html#pooled-analysis",
    "href": "4-datashield-pooled.html#pooled-analysis",
    "title": "4. Pooled and study-level functions",
    "section": "",
    "text": "How we can achieve that?\nIn many cases, it is not trivial to achieve this. But to dip our toes into the matter, let’s discuss a simple case. Let’s say we want to compute the mean value of a variable across multiple center.\n\n\n\n\n\nclassDiagram\n    class Server 1{\n      - 10 observations\n      - Mean: 2\n    }\n    class Server 2{\n      - 5 observations\n      - Mean: 4\n    }\n    class Server 3{\n      - 16 observations\n      - Mean: 8\n    }\n    Client &lt;|-- Server 1\n    Client &lt;|-- Server 2\n    Client &lt;|-- Server 3\n    Client : Has all info from\n    Client : the servers.\n    Client : Just has to perform\n    Client : simple maths.\n\n\n\n\n\n\nWe can recieve information from all the different servers (non-disclosive statistics) and with some simple maths on the client, work out a solution for the global mean.\n\\[\n\\mu_{pooled}=\\frac{\\sum_{i=1}^{n}N_{i} \\mu_i}{\\sum_{i=1}^{n}N_i}\n\\]\nWhere \\(\\mu_i\\) is the server \\(i\\) average and \\(N_i\\) is the server \\(i\\) number of observations.\n\n\nWhat to do on non trivial cases?\nThe mean computation is certainly a very easy example. However, we might be interested on performing much more advanced statistical methods on our new packages. Is at that point that our minds have to start working hard, as every method will have each own solution.\nOne option is to look for solutions in parallelized computer algorithms. If we make a little mental exercise, we can envision the DataSHIELD architecture as a computer CPU with some constraints.\nWhere each server is a CPU core and they are all orchestrated by a master.\n\nEach node/core has access to one part of the data at all computation time.\nThis data is horizontally partitioned.\nNode/cores can communicate with each other, but just with non-disclosive statistics.\nNode/cores can communicate with the manager/client, but just with non-disclosive statistics.\nManager/client can communicate with all node/cores, and send them pretty much anything.\n\nWith this information in our heads, we can review the literature of already solved parallelization problems on computer science journals, and maybe find algorithms that can be adapted.\nNext obvious option is to dig deep into the statistics of our particular problem and work ourselves a solution to solve it.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>4. Pooled and study-level functions</span>"
    ]
  },
  {
    "objectID": "4-datashield-pooled.html#meta-analysis",
    "href": "4-datashield-pooled.html#meta-analysis",
    "title": "4. Pooled and study-level functions",
    "section": "Meta analysis",
    "text": "Meta analysis\nIt could be that we do not find a solution to our pooled problem, or that we are not interested on that at all! For that reason we can talk about performing meta analysis or study-level functions.\nThis kind of functions are fundamentally simpler when it comes to design/implementation and (most importantly) disclosure control. On this kind of functions each server will compute a statistic and send it to the client; then, on the client this statistics will be analyzed using meta-analysis techniques.\nMeta-analysis itself is out of scope for this workshop, however, in R there is a very strong package to perform that, called metafor.\n\n\n\n\n\nclassDiagram\n    class Server 1{\n      - Statistics 1\n    }\n    class Server 2{\n      - Statistics 2\n    }\n    class Server 3{\n      - Statistics 3\n    }\n    Client &lt;|-- Server 1\n    Client &lt;|-- Server 2\n    Client &lt;|-- Server 3\n    Client : Has all info from\n    Client : the servers.\n    Client : Just has to perform\n    Client : meta-analysis.\n\n\n\n\n\n\nWhen developing this kind of functions, the developer has to just implement a function and be sure that the statistics returned by it are non-disclosive. Then, the developer has the option to include the meta-analysis step on the client function, or leave that to the researcher to use their prefered method.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>4. Pooled and study-level functions</span>"
    ]
  },
  {
    "objectID": "4-datashield-pooled.html#exercise-4",
    "href": "4-datashield-pooled.html#exercise-4",
    "title": "4. Pooled and study-level functions",
    "section": "Exercise 4",
    "text": "Exercise 4\nOn this exercise we will continue developing our packages. This time we will implement the mean function we just described.\n\nOn the dsServer package create an aggregate function named meanDS, that takes as input a numeric vector and returns a list with 1) the mean and 2) the length of the input vector.\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\nImplement a filter to the meanDS function that checks for a minimum length of the vector in order to compute the statistic.\n\n\n\n\nOn the dsClient package create a function named ds.mean2 that calls the mean2DS function, recieves the results, and then combines them in order to output a pooled mean.\nTest your new development using DSLite. Is the mean right?\n\n\n\n\n\n\n\nExercise solution\n\n\n\n\n\nOpen in new tab",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>4. Pooled and study-level functions</span>"
    ]
  },
  {
    "objectID": "5-opal.html",
    "href": "5-opal.html",
    "title": "5. Uploading packages to servers",
    "section": "",
    "text": "Opal\nOpal, developed by OBiBa, is a comprehensive core data management application that plays a vital role in the DataSHIELD infrastructure. This server application delivers a wide range of tools for importing, transforming, and describing data, as well as managing subject identifiers during data import and export processes.\nIn order to upload our server packages to it, we have two distinct methods 1 using the opal web interface, and 2 using the opalr package from our computer. We will focus on the second method on this workshop.\nThe opalr package offers us many administration functionalities; installing packages, uploading data, managing permissions…",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>5. Uploading packages to servers</span>"
    ]
  },
  {
    "objectID": "5-opal.html#opal",
    "href": "5-opal.html#opal",
    "title": "5. Uploading packages to servers",
    "section": "",
    "text": "Installing a GitHub hosted package\nThe first option that we will explore is to install a package that is hosted on a GitHub repository. To do that we will do the following.\n\no &lt;- opalr::opal.login(\n    username = \"user\",\n    password = \"password\",\n    url = \"https://myopal.org\"\n)\nopalr::dsadmin.install_github_package(\n    opal = o,\n    pkg = \"repo/package\",\n    ref = \"main\",\n    profile = \"default\"\n)\n\nThe procedure is quite similar to the one of using DataSHIELD, first you need to create a connection to Opal, and then you perform operations on it.\n\n\n\n\n\n\nWarning\n\n\n\nIn order to sucessfully install packages on the Opal, we have to login using an account with administrator privileges. On real world deployments probably we will not have them.\n\n\n\n\nInstalling a local package\nThe second case corresponds to not having the package on GitHub, or maybe in the case we want to test it on an real server before actually putting the code on GitHub.\nFortunatelly opalr also offers the option of uploading the package we have on our computer to the Opal server. In order to do that we have to run the following code\n\no &lt;- opalr::opal.login(\n    username = \"user\",\n    password = \"password\",\n    url = \"https://myopal.org\"\n)\n\nopalr::dsadmin.install_local_package.install_github_package(\n    opal = o,\n    path = devtools::build(),\n    profile = \"default\"\n)\n\n\n\n\n\n\n\nWarning\n\n\n\nFor this to work we need to be running the R session on the working directory where our package is located. We can check our working directory with getwd() and change it with setwd(\"/our/new/path\").",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>5. Uploading packages to servers</span>"
    ]
  },
  {
    "objectID": "5-opal.html#exercise-5",
    "href": "5-opal.html#exercise-5",
    "title": "5. Uploading packages to servers",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nFind the administration credentials for the opal-demo.obiba.org server.\n\n\n\n\n\n\n\nCredentials\n\n\n\n\n\nUsername: administrator\nPassword: password\n\n\n\n\nPush the package we developed throughout this workshop (dsServer) to the Opal server.\nTest that the package works on the Opal server.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>5. Uploading packages to servers</span>"
    ]
  }
]